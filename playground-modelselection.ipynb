{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development grounds for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from vehicle_detector import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, SpatialDropout2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded..\n"
     ]
    }
   ],
   "source": [
    "def get_data(sample_size=18458):    \n",
    "    notcar_data_folders = ['./data/non-vehicles/Extras',\n",
    "                           './data/non-vehicles/GTI']\n",
    "\n",
    "    car_data_folders    = ['./data/vehicles/GTI_MiddleClose',\n",
    "                            './data/vehicles/GTI_Far',\n",
    "                            './data/vehicles/KITTI_extracted',\n",
    "                            './data/vehicles/GTI_Right',\n",
    "                            './data/vehicles/GTI_Left']\n",
    "\n",
    "    cars = []\n",
    "    notcars = []\n",
    "    y_one_hot = []\n",
    "    for folder in notcar_data_folders:\n",
    "        image_paths =glob.glob(folder+'/*')\n",
    "        for path in image_paths:\n",
    "            notcars.append(cv2.imread(path))\n",
    "            # One_hot_label encoding\n",
    "            y_one_hot.append([0,1])\n",
    "            if len(notcars) == sample_size:\n",
    "                break\n",
    "        if len(notcars) == sample_size:\n",
    "                break\n",
    "\n",
    "\n",
    "    for folder in car_data_folders:\n",
    "        image_paths =glob.glob(folder+'/*')\n",
    "        for path in image_paths:\n",
    "            cars.append(cv2.imread(path))\n",
    "            y_one_hot.append([1,0])\n",
    "            # One_hot_label encoding\n",
    "            if len(cars) == sample_size:\n",
    "                break\n",
    "        if len(cars) == sample_size:\n",
    "                break\n",
    "\n",
    "\n",
    "    cars = np.array(cars)\n",
    "    notcars = np.array(notcars)\n",
    "    y_one_hot = np.array(y_one_hot)\n",
    "\n",
    "    X = np.concatenate((cars, notcars), axis=0)\n",
    "\n",
    "    del cars\n",
    "    del notcars\n",
    "    \n",
    "    with open('./data/data.p', 'wb') as f:\n",
    "        pickle.dump((X, y_one_hot), f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Uncomment for getting new samples sizes        \n",
    "get_data(sample_size=1000)\n",
    "\n",
    "with open('./data/data.p', 'rb') as f:\n",
    "    X, y_one_hot = pickle.load(f)\n",
    "print('loaded..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resize_to_target_size(image):\n",
    "    TARGET_SIZE = (64,64)\n",
    "    return cv2.resize(image, TARGET_SIZE)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = resize_to_target_size(image)\n",
    "    image = image.astype(np.float32)\n",
    "    # Normalize image\n",
    "    image = image / 255.0 - 0.5\n",
    "    return image\n",
    "\n",
    "X_normalized = []\n",
    "\n",
    "for img in X:\n",
    "    X_normalized.append(preprocess_image(img))\n",
    "    \n",
    "X_normalized = np.array(X_normalized)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized,\n",
    "                                                    y_one_hot,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1350 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1350/1350 [==============================] - 19s - loss: 0.3315 - acc: 0.8548 - val_loss: 0.1238 - val_acc: 0.9467\n",
      "Epoch 2/5\n",
      "1350/1350 [==============================] - 19s - loss: 0.0908 - acc: 0.9704 - val_loss: 0.0518 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "1350/1350 [==============================] - 17s - loss: 0.0359 - acc: 0.9889 - val_loss: 0.0315 - val_acc: 0.9933\n",
      "Epoch 4/5\n",
      "1350/1350 [==============================] - 17s - loss: 0.0198 - acc: 0.9985 - val_loss: 0.0294 - val_acc: 0.9867\n",
      "Epoch 5/5\n",
      "1350/1350 [==============================] - 16s - loss: 0.0180 - acc: 0.9933 - val_loss: 0.0160 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb53913da0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# TODO: Compile and train the model\n",
    "model.compile('adam', 'binary_crossentropy', ['accuracy'])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          nb_epoch=5,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./models/keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Evaluate model on test data\n",
    "\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdc]",
   "language": "python",
   "name": "conda-env-sdc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
